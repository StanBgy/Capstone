{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required Libraries \n",
    "\n",
    "#Miscallenous \n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Deep learning Libraries \n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.python.ops import array_ops\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications import Xception\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "#Evaluation \n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abf7ce",
   "metadata": {},
   "source": [
    "# Let's first initiate the paths to load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = #Your base file, contains all the data. \n",
    "TRAIN_DIR = 'stage_2_train/'\n",
    "TEST_DIR = 'stage_2_test/'\n",
    "train_df = pd.read_csv(BASE_PATH + 'stage_2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e8cef",
   "metadata": {},
   "source": [
    "Then, split the name and type sections of each ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(BASE_PATH + 'stage_2_sample_submission.csv')\n",
    "\n",
    "train_df['filename'] = train_df['ID'].apply(lambda x: \"ID_\" + x.split('_')[1] + \".png\")\n",
    "train_df['type'] = train_df['ID'].apply(lambda x: x.split('_')[2])\n",
    "x['filename'] = x['ID'].apply(lambda x: \"ID_\" + x.split('_')[1] + \".png\")\n",
    "x['type'] = x['ID'].apply(lambda x: x.split('_')[2])\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce747f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(x.filename.unique(), columns=['filename'])\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c178e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = x[['Label', 'filename', 'type']].drop_duplicates().pivot(\n",
    "    index='filename', columns='type', values='Label').reset_index()\n",
    "print(test_df.shape)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f754ba",
   "metadata": {},
   "source": [
    "Next, we pivot the dataframe to create the one that will be use to load the data in the datagenerators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select 400,000 random images \n",
    "\n",
    "np.random.seed(2019)\n",
    "sample_files = np.random.choice(os.listdir(BASE_PATH + TRAIN_DIR), 400000)\n",
    "sample_df = train_df[train_df.filename.apply(lambda x: x.replace('.png', '.dcm')).isin(sample_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba8064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot_df = sample_df[['Label', 'filename', 'type']].drop_duplicates().pivot(\n",
    "    index='filename', columns='type', values='Label').reset_index()\n",
    "print(pivot_df.shape)\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1edeaf",
   "metadata": {},
   "source": [
    "Then, we create the validation dataframe, taking a 15% split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f036d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the balanced data approach: do not run the randomizer, pivot from the train_df\n",
    "#then, uncomment the following cells: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This speoarates the training data into two data frame, one only containing the \n",
    "#images ID labeled as \"No hemorrages\" and the ones labeled as \"any hemorrhage\"\n",
    "\n",
    "#For the \"only subudral\" approach: the same can be done, but select 'subdural' instead of 'any'\n",
    "#Additionaly, the Output layer of the model needs to be changed to return only 1 probabilities and not 6\n",
    "#and the DataGenerators need to be modified to only consider the 'subdural' labels\n",
    "\n",
    "\n",
    "#one_df = pivot_df.drop(pivot_df.loc[pivot_df['any']==0].index)\n",
    "#one_df\n",
    "\n",
    "#zero_df = pivot_df.drop(pivot_df.loc[pivot_df['any']==1].index)\n",
    "#zero_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cedd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot_df = pd.concat([zero_df, one_df])\n",
    "#pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b26bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pivot_df.sample(int(len(pivot_df) * 0.15))  \n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pivot_df[~(pivot_df.filename.isin(validation_df.filename))]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a sample of 20000 from the testing set, just to make predicitions slightly faster \n",
    "\n",
    "np.random.seed(2019)\n",
    "sample_test = np.random.choice(os.listdir(BASE_PATH + TEST_DIR), 20000) \n",
    "test_sample_df = test_df[test_df.filename.apply(lambda x: x.replace('.png', '.dcm')).isin(sample_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ebc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a71218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We initiatie a list of labels, for future validation (it will be required when computing the ROC\n",
    "#curves, the confusion matrices, etc)\n",
    "y_true = []\n",
    "for i in range(len(validation_df)): \n",
    "    y_true.append(validation_df.iloc[i,1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a550243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is necessary for the balanaced data approach, to create the list of the \n",
    "#IDs included in the training dataframe used in this approach \n",
    "\n",
    "#pivot_df['filename'] = pivot_df.filename.apply(lambda x: x.replace('.png', '.dcm'))\n",
    "#sample_files = sample_df[\"filename\"].to_numpy()\n",
    "#len(sample_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_df.head())\n",
    "print(validation_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb6ebe",
   "metadata": {},
   "source": [
    "# The next section will include the image preprocessing functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_hu(scan): \n",
    "    image = np.stack([scan.pixel_array])\n",
    "    image = image.astype(np.int16) \n",
    "    \n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    intercept = scan.RescaleIntercept\n",
    "    slope = scan.RescaleSlope\n",
    "    \n",
    "    if slope != 1: \n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "    \n",
    "    image += np.int16(intercept) \n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68699c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the windowing function, all credit goes to:\n",
    "#https://github.com/darraghdog/rsna/blob/master/scripts/prepare_meta_dicom.py\n",
    "\n",
    "def apply_window(image, center, width):\n",
    "    image = image.copy()\n",
    "    min_value = center - width // 2\n",
    "    max_value = center + width // 2\n",
    "    image[image < min_value] = min_value\n",
    "    image[image > max_value] = max_value\n",
    "    return image\n",
    "\n",
    "\n",
    "def apply_window_policy(image):\n",
    "\n",
    "    image1 = apply_window(image, 40, 80) # brain\n",
    "    image2 = apply_window(image, 80, 200) # subdural\n",
    "    image3 = apply_window(image, 40, 380) # bone\n",
    "    image1 = (image1 - 0) / 80\n",
    "    image2 = (image2 - (-20)) / 200\n",
    "    image3 = (image3 - (-150)) / 380\n",
    "    image = np.array([\n",
    "        image1 - image1.mean(),\n",
    "        image2 - image2.mean(),\n",
    "        image3 - image3.mean(),\n",
    "    ]).transpose(1,2,0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad969658",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/save_dir/'   # Save the new images in this file \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_resize(filenames, load_dir):    \n",
    "    \n",
    "    for filename in tqdm(filenames):\n",
    "        try:\n",
    "            path = load_dir + filename\n",
    "            new_path = save_dir + filename.replace('.dcm', '.png')\n",
    "            dcm = pydicom.dcmread(path)\n",
    "            image = get_pixels_hu(dcm)\n",
    "            image = apply_window_policy(image[0])\n",
    "            image -= image.min((0,1))\n",
    "            image = (255*image).astype(np.uint8)\n",
    "            image = cv2.resize(image, (299, 299)) \n",
    "            final_image = cv2.imwrite(new_path, image)\n",
    "            \n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d14a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_resize(filenames=os.listdir(BASE_PATH + TRAIN_DIR), load_dir=BASE_PATH + TRAIN_DIR)\n",
    "save_and_resize(filenames=os.listdir(BASE_PATH + TEST_DIR), load_dir=BASE_PATH + TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65434b",
   "metadata": {},
   "source": [
    "# Now, we can initiate the Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():    \n",
    "    base_model = Xception(weights = 'imagenet', include_top = False, input_shape = (299,299,3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    y_pred = Dense(6, activation = 'sigmoid')(x)\n",
    "    #y_pred = Dense(1, activation = 'sigmoid')(x)  #(only subdural approach)\n",
    "\n",
    "    return Model(inputs = base_model.input, outputs = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 0.00005), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "            #metrics = [tf.keras.metrics.AUC()])\n",
    "            #metrics = [tf.keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "            #metrics = [tf.keras.metrics.SpecificityAtSensitivity(0.5)]) for the additional approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee1884",
   "metadata": {},
   "source": [
    "# And the data generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b805f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 # or 32\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator()\n",
    "\n",
    "def create_test_gen():\n",
    "    return ImageDataGenerator().flow_from_dataframe(\n",
    "        test_sample_df,\n",
    "        directory=  '/save_dir/',\n",
    "        x_col='filename',\n",
    "        class_mode=None,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "def create_train_gen(datagen):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        training_df, \n",
    "        directory='/save_dir/',\n",
    "        \n",
    "        x_col='filename', \n",
    "        y_col=['any', 'epidural', 'intraparenchymal', \n",
    "               'intraventricular', 'subarachnoid', 'subdural'], #Remove all but subudral for the only subdrual approach\n",
    "        class_mode='other',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BATCH_SIZE,   \n",
    "       \n",
    "    )\n",
    "def create_val_gen(datagen): \n",
    "    return datagen.flow_from_dataframe(\n",
    "        validation_df, \n",
    "        directory='/save_dir/',\n",
    "        \n",
    "        x_col='filename', \n",
    "        y_col=['any', 'epidural', 'intraparenchymal', \n",
    "               'intraventricular', 'subarachnoid', 'subdural'], #Remove all but subudral for the only subdrual approach\n",
    "        class_mode='other',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_datagen()\n",
    "train_gen = create_train_gen(generator)\n",
    "val_gen = create_val_gen(generator)\n",
    "test_gen = create_test_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5268049",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2dab5",
   "metadata": {},
   "source": [
    "# This cell runs the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e48289",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'effnetb4.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "Early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=1, \n",
    "                                              mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "total_steps = sample_files.shape[0] // BATCH_SIZE\n",
    "total_steps = total_steps // 4\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch = total_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=total_steps * 0.15,\n",
    "    callbacks=[checkpoint, Early_stop],\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy'] #This needs to be changed if the metric is changed too! \n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "fig = plt.figure()\n",
    "fig.savefig('acc.png')\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939b7c6",
   "metadata": {},
   "source": [
    "# Now we make predictions: \n",
    "first on the validation set, to ensure our model predicts hemorrhages correct, and then on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict_generator(val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbef19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47925dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate a list of rounded predictions. \n",
    "\n",
    "y_preds = []\n",
    "for i in range(len(val_preds)):\n",
    "    y_preds.append(0)\n",
    "    for value in val_preds[i]: \n",
    "        if value > 0.5: \n",
    "            y_preds[i] = 1\n",
    "            break\n",
    "            \n",
    "        \n",
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fce208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('2*2 Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_preds))\n",
    "cm = confusion_matrix(y_true, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools   \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['no hemorrhage', 'has hemorrhage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1441fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = []\n",
    "for pred in val_preds: \n",
    "    predictions_list.append(pred)\n",
    "\n",
    "len(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_frame = validation_df.drop(['filename'], axis=1)\n",
    "validation_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394aa4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(predictions_list) == len(validation_frame): \n",
    "    validation_frame.iloc[:,:] = predictions_list\n",
    "else: \n",
    "    print(\"fix this issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a53d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_frame.insert(0, \"filename\", validation_df.filename)\n",
    "validation_frame.insert(7, \"true_any\" ,validation_df.iloc[:,1])\n",
    "validation_frame.insert(8, \"true_epidural\", validation_df.epidural)\n",
    "validation_frame.insert(9, \"true_intraparenchymal\", validation_df.intraparenchymal)\n",
    "validation_frame.insert(10, \"true_intraventricular\", validation_df.intraventricular)\n",
    "validation_frame.insert(11, \"true_subarachnoid\", validation_df.subarachnoid)\n",
    "validation_frame.insert(12, \"true_subdural\", validation_df.subdural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): \n",
    "    if validation_frame.iloc[i,1] > 0.5: \n",
    "        print(\"ID is : \" + str(validation_frame.iloc[i,0]))\n",
    "        for j in range(1,7): \n",
    "            print(\"predicition = \" +  str(validation_frame.iloc[i,j]) )\n",
    "        for k in range(7,13): \n",
    "            print(\"true predicition = \" +  str(validation_frame.iloc[i,k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict_generator(test_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325cd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list_test = []\n",
    "for pred in test_preds: \n",
    "    predictions_list_test.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b833c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame =  test_sample_df.drop(['filename'], axis=1)\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.iloc[:,:] = predictions_list_test\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.insert(0, \"filename\", test_df.filename)\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for i in range(20): \n",
    "  \n",
    "    for j in range(1,7): \n",
    "        if test_frame.iloc[i,j] > 0.8: \n",
    "            path = '/kaggle/tmp/' + str(test_frame.iloc[i,0])\n",
    "            img = Image.open(path)\n",
    "            plt.imshow(img)\n",
    "            print(str(test_frame.iloc[i,0]) + \" has a probability: \"  + str(test_frame.iloc[i,j]) + \" for a '\" + str(test_frame.columns[j]) + \"' type of hemorrhage\")\n",
    "            plt.show()\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf2303",
   "metadata": {},
   "source": [
    "Lastly, a heatmap of the activation of the last layer of the model is made, taking the image with the highest prediction score in the validation set. This returns a nice methods to see what does the model \"sees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe693d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_preds = validation_frame['any']\n",
    "max_index = any_preds.idxmax()\n",
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fd1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_heatmap(): \n",
    "    highest_predicted_img = validation_frame.loc[max_index,'filename']\n",
    "    if validation_frame.loc[max_index, 'true_any'] == 1:\n",
    "        return highest_predicted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_predicted_img =  img_to_heatmap()\n",
    "highest_predicted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e462bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap \n",
    "#The code used to show the heatmake was taken from: https://keras.io/examples/vision/grad_cam/\n",
    "#Only slightly modified to fit this workflow and return the image with the highest predicition from the validtion set \n",
    "from IPython.display import Image, display\n",
    "\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"block14_sepconv2_act\"\n",
    "\n",
    "img_path = '/kaggle/tmp/' + highest_predicted_img\n",
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    \n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (299, 299)\n",
    "\n",
    "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154230fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38268b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
