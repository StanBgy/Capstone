{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required Libraries \n",
    "\n",
    "#Miscallenous \n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Deep Learning Libraries \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from math import ceil, floor\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abf7ce",
   "metadata": {},
   "source": [
    "# Let's first initiate the paths to load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = # your path\n",
    "TRAIN_DIR = 'stage_2_train/'\n",
    "TEST_DIR = 'stage_2_test/'\n",
    "train_df = pd.read_csv(BASE_PATH + 'stage_2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e8cef",
   "metadata": {},
   "source": [
    "Then, split the name and type sections of each ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(BASE_PATH + 'stage_2_sample_submission.csv')\n",
    "\n",
    "train_df['filename'] = train_df['ID'].apply(lambda x: \"ID_\" + x.split('_')[1] + \".png\")\n",
    "train_df['type'] = train_df['ID'].apply(lambda x: x.split('_')[2])\n",
    "x['filename'] = x['ID'].apply(lambda x: \"ID_\" + x.split('_')[1] + \".png\")\n",
    "x['type'] = x['ID'].apply(lambda x: x.split('_')[2])\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce747f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test.filename.unique(), columns=['filename'])\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c178e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sub_df[['Label', 'filename', 'type']].drop_duplicates().pivot(\n",
    "    index='filename', columns='type', values='Label').reset_index()\n",
    "print(test_df.shape)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f754ba",
   "metadata": {},
   "source": [
    "Next, we pivot the dataframe to create the one that will be use to load the data in the datagenerators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba8064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot_df = train_df[['Label', 'filename', 'type']].drop_duplicates().pivot(\n",
    "    index='filename', columns='type', values='Label').reset_index()\n",
    "print(pivot_df.shape)\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1edeaf",
   "metadata": {},
   "source": [
    "Then, we create the validation dataframe, taking a 15% split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b26bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pivot_df.sample(int(len(pivot_df) * 0.15))  \n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pivot_df[~(pivot_df.filename.isin(validation_df.filename))]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb6ebe",
   "metadata": {},
   "source": [
    "# The next section will include the image preprocessing functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_hu(scan): \n",
    "    image = np.stack([scan.pixel_array])\n",
    "    image = image.astype(np.int16) \n",
    "    \n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    intercept = scan.RescaleIntercept\n",
    "    slope = scan.RescaleSlope\n",
    "    \n",
    "    if slope != 1: \n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "    \n",
    "    image += np.int16(intercept) \n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68699c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the windowing function, all credit goes to:\n",
    "#https://github.com/darraghdog/rsna/blob/master/scripts/prepare_meta_dicom.py\n",
    "\n",
    "def apply_window(image, center, width):\n",
    "    image = image.copy()\n",
    "    min_value = center - width // 2\n",
    "    max_value = center + width // 2\n",
    "    image[image < min_value] = min_value\n",
    "    image[image > max_value] = max_value\n",
    "    return image\n",
    "\n",
    "\n",
    "def apply_window_policy(image):\n",
    "\n",
    "    image1 = apply_window(image, 40, 80) # brain\n",
    "    image2 = apply_window(image, 80, 200) # subdural\n",
    "    image3 = apply_window(image, 40, 380) # bone\n",
    "    image1 = (image1 - 0) / 80\n",
    "    image2 = (image2 - (-20)) / 200\n",
    "    image3 = (image3 - (-150)) / 380\n",
    "    image = np.array([\n",
    "        image1 - image1.mean(),\n",
    "        image2 - image2.mean(),\n",
    "        image3 - image3.mean(),\n",
    "    ]).transpose(1,2,0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad969658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_dir = '/save_dir/'   # Save the new images in this file \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_resize(filenames, load_dir):    \n",
    "    \n",
    "    for filename in tqdm(filenames):\n",
    "        try:\n",
    "            path = load_dir + filename\n",
    "            new_path = save_dir + filename.replace('.dcm', '.png')\n",
    "            dcm = pydicom.dcmread(path)\n",
    "            image = get_pixels_hu(dcm)\n",
    "            image = apply_window_policy(image[0])\n",
    "            image -= image.min((0,1))\n",
    "            image = (255*image).astype(np.uint8)\n",
    "            image = cv2.resize(image, (299, 299)) \n",
    "            final_image = cv2.imwrite(new_path, image)\n",
    "            \n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d14a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_resize(filenames=os.listdir(BASE_PATH + TRAIN_DIR), load_dir=BASE_PATH + TRAIN_DIR)\n",
    "save_and_resize(filenames=os.listdir(BASE_PATH + TEST_DIR), load_dir=BASE_PATH + TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65434b",
   "metadata": {},
   "source": [
    "# Now, we can initiate the Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():    \n",
    "    base_model = Xception(weights = 'imagenet', include_top = False, input_shape = (299,299,3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    y_pred = Dense(6, activation = 'sigmoid')(x)\n",
    "\n",
    "    return Model(inputs = base_model.input, outputs = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 0.00005), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee1884",
   "metadata": {},
   "source": [
    "# And the data generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b805f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 # or 32\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator()\n",
    "\n",
    "def create_test_gen():\n",
    "    return ImageDataGenerator().flow_from_dataframe(\n",
    "        test_sample_df,\n",
    "        directory=  '/save_dir/',\n",
    "        x_col='filename',\n",
    "        class_mode=None,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "def create_train_gen(datagen):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        training_df, \n",
    "        directory='/save_dir/',\n",
    "        \n",
    "        x_col='filename', \n",
    "        y_col=['any', 'epidural', 'intraparenchymal', \n",
    "               'intraventricular', 'subarachnoid', 'subdural'],\n",
    "        class_mode='other',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BATCH_SIZE,   \n",
    "       \n",
    "    )\n",
    "def create_val_gen(datagen): \n",
    "    return datagen.flow_from_dataframe(\n",
    "        validation_df, \n",
    "        directory='/save_dir/',\n",
    "        \n",
    "        x_col='filename', \n",
    "        y_col=['any', 'epidural', 'intraparenchymal', \n",
    "               'intraventricular', 'subarachnoid', 'subdural'],\n",
    "        class_mode='other',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_datagen()\n",
    "train_gen = create_train_gen(generator)\n",
    "val_gen = create_val_gen(generator)\n",
    "test_gen = create_test_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5268049",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2dab5",
   "metadata": {},
   "source": [
    "# This cell runs the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e48289",
   "metadata": {},
   "outputs": [],
   "source": [
    "Early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=1, \n",
    "                                              mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "STEPS = len(pivot_df) // BATCH_SIZE\n",
    "STEPS = STEPS // 4\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch = STEPS,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=STEPS * 0.15,\n",
    "    callbacks=[Early_stop],\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "fig = plt.figure()\n",
    "fig.savefig('acc.png')\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939b7c6",
   "metadata": {},
   "source": [
    "# Now we make predictions: \n",
    "first on the validation set, to ensure our model predicts hemorrhages correct, and then on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict_generator(val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbef19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = []\n",
    "for pred in val_preds: \n",
    "    predictions_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47925dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = []\n",
    "for pred in val_preds: \n",
    "    predictions_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_frame.iloc[:,:] = predictions_list\n",
    "validation_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a53d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_frame.insert(0, \"filename\", validation_df.filename)\n",
    "validation_frame.insert(7, \"true_any\" ,validation_df.iloc[:,1])\n",
    "validation_frame.insert(8, \"true_epidural\", validation_df.epidural)\n",
    "validation_frame.insert(9, \"true_intraparenchymal\", validation_df.intraparenchymal)\n",
    "validation_frame.insert(10, \"true_intraventricular\", validation_df.intraventricular)\n",
    "validation_frame.insert(11, \"true_subarachnoid\", validation_df.subarachnoid)\n",
    "validation_frame.insert(12, \"true_subdural\", validation_df.subdural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10): \n",
    "    if validation_frame.iloc[i,1] > 0.5: \n",
    "        print(\"ID is : \" + str(validation_frame.iloc[i,0]))\n",
    "        for j in range(1,7): \n",
    "            print(\"predicition = \" +  str(validation_frame.iloc[i,j]) )\n",
    "        for k in range(7,13): \n",
    "            print(\"true predicition = \" +  str(validation_frame.iloc[i,k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe693d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_preds = validation_frame['any']\n",
    "max_index = any_preds.idxmax()\n",
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fd1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_heatmap(): \n",
    "    highest_predicted_img = validation_frame.loc[max_index,'filename']\n",
    "    if validation_frame.loc[max_index, 'true_any'] == 1:\n",
    "        return highest_predicted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_predicted_img =  img_to_heatmap()\n",
    "highest_predicted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict_generator(test_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325cd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list_test = []\n",
    "for pred in test_preds: \n",
    "    predictions_list_test.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b833c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame =  test_sample_df.drop(['filename'], axis=1)\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.iloc[:,:] = predictions_list_test\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.insert(0, \"filename\", test_df.filename)\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_frame)): \n",
    "  \n",
    "    for j in range(1,2): \n",
    "        if test_frame.iloc[i,j] > 0.8: \n",
    "            print(\"predicition for image ID \" + str(test_frame.iloc[i,0]) + \" is : \"  + str(test_frame.iloc[i,j]) )\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf2303",
   "metadata": {},
   "source": [
    "Lastly, a heatmap of the activation of the last layer of the model is made, taking the image with the highest prediction score in the validation set. This returns a nice methods to see what does the model \"sees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e462bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap \n",
    "#The code used to show the heatmake was taken from: https://keras.io/examples/vision/grad_cam/\n",
    "#Only slightly modified to fit this workflow and return the image with the highest predicition from the validtion set \n",
    "from IPython.display import Image, display\n",
    "\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"block14_sepconv2_act\"\n",
    "\n",
    "img_path = '/kaggle/tmp/' + highest_predicted_img\n",
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    \n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (299, 299)\n",
    "\n",
    "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154230fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38268b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
